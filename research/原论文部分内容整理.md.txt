> 原论文中部分内容的整理与解释

## 相关工作

- 无监督分割
	无参方法label transfer, matching, distance evaluation
	手工特征(handcrafted features) boundary, superpixels
	一些方法只关注了分割，而语义分割还需要关注分类
	提供了先验知识，因此一些无监督的模型是基于预训练的表达(segment sorting, mutual information maximization, region contrastive learning, geometric consistency)
	难以从语义分割过度到大规模语义分割：由于训练数据集过少、策略简单，不能发挥从大数据集中能学习到丰富表征的优势，也忽略了大数据集带来的计算开销；问题定义和评价标准不明，一些方法使用了先验知识，难以评估
- 自监督表征学习
  大规模语义分析使用了一些自监督策略
  - Contrastive-based SSL
  	使用相对损失评价相似度——“推开”差异，“拥抱”相似
  - Non-contrastive-based SSL

  这两种方法对于种类相关的任务贡献不大，因为相同类的实例不一定有共享的特征

  - Clustering-based SSL
  	让一组图片能够“聚合”，聚类质心可以作为种类的表达
  - Pixel-level SSL
  	transfer learning效果好，但同样忽略了语义类别
- 弱监督语义分割
	所需要的先验知识、网络结构是LUSS难以应用的
	affinity prediction, region separation, boundary refinement, joint learning, and sub-category exploration, to improve LUSS models
	

## 评估方法
- 完全无监督的评估协议
	训练不需要标注，需要验证/测试集
	实现了图像级的匹配模式（可以用更有效的匹配模式）
	类别匹配存在缺陷，存在意料外的错匹配（没读懂这部分，可能是改进的方向）
- 半监督评估协议
	对LUSS模型使用1%标注过的训练集，不用再用生成的类别匹配真实类别
- 距离匹配评估协议
	将训练集和测试集在像素级的嵌入进行相似度比较
	对验证集中的嵌入，找到前k个在训练集中相似的嵌入和标签，每个像素的标签由这k个嵌入和标签来决定

## 挑战

1. 无监督的形状和语义表征学习
2. 形状和类别的表征不应冲突（歧义）
3. 高效率地为每个像素打标签（生成的伪标签）
4. 训练效率问题

## PASS方法

![image-20230411185213080](assets/image-20230411185213080.png)

### 1. 基于自监督模型学习形状和语义表征

1. 像素到像素的非增强(non-contrastive)表征分配策略——**学习形状表征的同时减小对语义表征的负面影响**

   相同语义区域的像素，或者不同视角下的同一图像对应的像素，应当有相同的表达。

   过度关注像素的区分会导致同一实例的语义不一致$\rightarrow$**像素到像素的非增强(non-contrastive)表征分配策略**

   ![image-20230411190220170](assets/image-20230411190220170.png)

   损失函数

   ![image-20230411191355087](assets/image-20230411191355087.png)

   > 图只是表示了一部分，对于重叠像素的embedding，都需要分别通过Predictor，再比较相似度（即计算损失）
   >
   > 关于stop gradient：[何恺明团队：stop gradient是**孪生网络对比学习**成功的关键](https://blog.csdn.net/xixiaoyaoww/article/details/110605756)
   >
   > ![image-20230411191656028](assets/image-20230411191656028.png)
   >
   > 该图表示得应该更容易理解一些

2. 由深到浅的监督策略增强网络中间层的特征表达——**浅层网络得到的特征同样重要**

   ![image-20230411192712061](assets/image-20230411192712061.png)

   图像级embedding的计算。这里增加了$M_k^s$即像素级的映射，实际上减少了语义的collapse

   ![image-20230411192940755](assets/image-20230411192940755.png)

   损失函数。一张图像最后一级的embedding可以看作另一张图像各级的标注（用深层的语义去指导反向传播）。

   ![image-20230411193232435](assets/image-20230411193232435.png)

3. 整体损失函数

   $L_e$是现有方法的损失

   ![image-20230411193709806](assets/image-20230411193709806.png)

### 2. 基于像素注意力的像素标签生成

对训练得到的特征进行聚类。

性能问题：直接对像素embedding进行聚类太耗时；或者做池化减少计算量，将导致语义无关像素影响结果。

1. 像素注意力机制与微调

   不同像素的重要性是不同的，包含更多语义信息的像素应该更重要

   为像素增加了头部标注，以期通过微调找到语义相关区域——提高了聚类效果和形状划分质量

   像素注意力定义如下。在微调时，像素特征的范式乘以该系统即实现不同像素重要性的区分。

   ![image-20230411194923685](assets/image-20230411194923685.png)

   实际效果比较明显。与语义相关区域几乎都被高亮了。

   ![image-20230411201545090](assets/image-20230411201545090.png)

2. 生成标签

   在像素注意力基础上，通过通过聚类的质心，为像素生成伪标签。

   判定像素是否为语义丰富：设定阈值，求平均维度下的注意力系数，看是否超过阈值。

   ![image-20230411204125983](assets/image-20230411204125983.png)

### 3. 微调（提升语义分割质量）

通过上述步骤，实现了自监督过程，得到伪标签作为训练集的标注。接下来做一般的分类任务，用像素embedding在卷积后的各个通道上的最大可能类别作为该像素的判定类别。

![image-20230411204805574](assets/image-20230411204805574.png)